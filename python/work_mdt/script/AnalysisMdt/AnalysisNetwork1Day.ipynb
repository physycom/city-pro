{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "with open(\"/home/aamad/Desktop/phd/codice/city-pro/config/ConfigPythonAnalysis.json\",\"r\") as f:\n",
    "    Dict =json.load(f)\n",
    "df = pd.read_csv(os.path.join(Dict[\"InputBaseDir\"],Dict[\"base_name\"] + '_' + Dict[\"StrDates\"][3] + '_' + Dict['StrDates'][3] + '_fcm_centers.csv'),delimiter = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   value_to_bin  value_to_average  bins\n",
      "0            10                 5  Bin4\n",
      "1             6                 3  Bin3\n",
      "2             1                 6  Bin1\n",
      "3             6                 2  Bin3\n",
      "4             5                 7  Bin2\n",
      "5             6                 4  Bin3\n",
      "6             7                 8  Bin3\n",
      "7             8                 1  Bin3\n",
      "8             9                 9  Bin4\n",
      "9            10                 2  Bin4\n",
      "   bins  value_to_average\n",
      "0  Bin1          6.000000\n",
      "1  Bin2          7.000000\n",
      "2  Bin3          3.600000\n",
      "3  Bin4          5.333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37565/3532013409.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  result = df.groupby('bins')['value_to_average'].mean().reset_index()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create a sample DataFrame\n",
    "data = {\n",
    "    'value_to_bin': [10, 6, 1, 6, 5, 6, 7, 8, 9, 10],\n",
    "    'value_to_average': [5, 3, 6, 2, 7, 4, 8, 1, 9, 2]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Bin the data in 'value_to_bin'\n",
    "bins = [0, 3, 6, 9, 12]  # Define bin edges\n",
    "labels = ['Bin1', 'Bin2', 'Bin3', 'Bin4']  # Define bin labels\n",
    "\n",
    "df['bins'] = pd.cut(df['value_to_bin'], bins=bins, labels=labels, right=False)\n",
    "print(df)\n",
    "# Step 3: Group by the bins and compute the average of 'value_to_average'\n",
    "result = df.groupby('bins')['value_to_average'].mean().reset_index()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'localhost:0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"DISPLAY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape: (6, 2)\n",
      "┌────────┬─────────────────────┐\n",
      "│ values ┆ values2bconditioned │\n",
      "│ ---    ┆ ---                 │\n",
      "│ i64    ┆ i64                 │\n",
      "╞════════╪═════════════════════╡\n",
      "│ 1      ┆ 1                   │\n",
      "│ 2      ┆ 2                   │\n",
      "│ 1      ┆ 1                   │\n",
      "│ 2      ┆ 2                   │\n",
      "│ 1      ┆ 1                   │\n",
      "│ 2      ┆ 2                   │\n",
      "└────────┴─────────────────────┘\n",
      "\n",
      "shape: (6, 2)\n",
      "┌────────┬─────────────────────┐\n",
      "│ values ┆ values2bconditioned │\n",
      "│ ---    ┆ ---                 │\n",
      "│ i64    ┆ i64                 │\n",
      "╞════════╪═════════════════════╡\n",
      "│ 3      ┆ 3                   │\n",
      "│ 4      ┆ 4                   │\n",
      "│ 3      ┆ 3                   │\n",
      "│ 4      ┆ 4                   │\n",
      "│ 3      ┆ 3                   │\n",
      "│ 4      ┆ 4                   │\n",
      "└────────┴─────────────────────┘\n",
      "\n",
      "shape: (6, 2)\n",
      "┌────────┬─────────────────────┐\n",
      "│ values ┆ values2bconditioned │\n",
      "│ ---    ┆ ---                 │\n",
      "│ i64    ┆ i64                 │\n",
      "╞════════╪═════════════════════╡\n",
      "│ 5      ┆ 5                   │\n",
      "│ 6      ┆ 6                   │\n",
      "│ 5      ┆ 5                   │\n",
      "│ 6      ┆ 6                   │\n",
      "│ 5      ┆ 5                   │\n",
      "│ 6      ┆ 6                   │\n",
      "└────────┴─────────────────────┘\n",
      "\n",
      "shape: (6, 2)\n",
      "┌────────┬─────────────────────┐\n",
      "│ values ┆ values2bconditioned │\n",
      "│ ---    ┆ ---                 │\n",
      "│ i64    ┆ i64                 │\n",
      "╞════════╪═════════════════════╡\n",
      "│ 7      ┆ 7                   │\n",
      "│ 8      ┆ 8                   │\n",
      "│ 7      ┆ 7                   │\n",
      "│ 8      ┆ 8                   │\n",
      "│ 7      ┆ 7                   │\n",
      "│ 8      ┆ 8                   │\n",
      "└────────┴─────────────────────┘\n",
      "\n",
      "shape: (6, 2)\n",
      "┌────────┬─────────────────────┐\n",
      "│ values ┆ values2bconditioned │\n",
      "│ ---    ┆ ---                 │\n",
      "│ i64    ┆ i64                 │\n",
      "╞════════╪═════════════════════╡\n",
      "│ 9      ┆ 9                   │\n",
      "│ 10     ┆ 10                  │\n",
      "│ 9      ┆ 9                   │\n",
      "│ 10     ┆ 10                  │\n",
      "│ 9      ┆ 9                   │\n",
      "│ 10     ┆ 10                  │\n",
      "└────────┴─────────────────────┘\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Expr' object has no attribute 'bucket'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mfilter((pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m bins[i]) \u001b[38;5;241m&\u001b[39m (pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m bins[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])))\n\u001b[1;32m     17\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[0;32m---> 18\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbins\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Expr' object has no attribute 'bucket'"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pl.DataFrame({\n",
    "    \"values\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,1, 2, 3, 4, 5, 6, 7, 8, 9, 10,1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"values2bconditioned\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,1, 2, 3, 4, 5, 6, 7, 8, 9, 10,1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "})\n",
    "\n",
    "# Create bins for 'values'\n",
    "n,bins = np.histogram(df['values'], bins=5)\n",
    "DictBins2Value = {\"binsvalue\":bins,\"countvalues\":n,\"binsvalues2bconditioned\":[],\"countvalues2bconditioned\":[]}\n",
    "for i in range(len(bins)-1):\n",
    "    print()\n",
    "    print(df.filter((pl.col(\"values\")>= bins[i]) & (pl.col(\"values\")<= bins[i+1])))\n",
    "df = df.with_columns(\n",
    "    pl.col(\"values\"), pl.col(\"values\").bucket(5).alias(\"bins\")\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': 'polars',\n",
       " '__doc__': None,\n",
       " '__package__': 'polars',\n",
       " '__loader__': <_frozen_importlib_external.SourceFileLoader at 0x7e55e4c36ed0>,\n",
       " '__spec__': ModuleSpec(name='polars', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7e55e4c36ed0>, origin='/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/__init__.py', submodule_search_locations=['/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars']),\n",
       " '__path__': ['/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars'],\n",
       " '__file__': '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/__init__.py',\n",
       " '__cached__': '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/__pycache__/__init__.cpython-312.pyc',\n",
       " '__builtins__': {'__name__': 'builtins',\n",
       "  '__doc__': \"Built-in functions, types, exceptions, and other objects.\\n\\nThis module provides direct access to all 'built-in'\\nidentifiers of Python; for example, builtins.len is\\nthe full name for the built-in function len().\\n\\nThis module is not normally accessed explicitly by most\\napplications, but can be useful in modules that provide\\nobjects with the same name as a built-in value, but in\\nwhich the built-in of that name is also needed.\",\n",
       "  '__package__': '',\n",
       "  '__loader__': _frozen_importlib.BuiltinImporter,\n",
       "  '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'),\n",
       "  '__build_class__': <function __build_class__>,\n",
       "  '__import__': <function __import__(name, globals=None, locals=None, fromlist=(), level=0)>,\n",
       "  'abs': <function abs(x, /)>,\n",
       "  'all': <function all(iterable, /)>,\n",
       "  'any': <function any(iterable, /)>,\n",
       "  'ascii': <function ascii(obj, /)>,\n",
       "  'bin': <function bin(number, /)>,\n",
       "  'breakpoint': <function breakpoint>,\n",
       "  'callable': <function callable(obj, /)>,\n",
       "  'chr': <function chr(i, /)>,\n",
       "  'compile': <function compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1, *, _feature_version=-1)>,\n",
       "  'delattr': <function delattr(obj, name, /)>,\n",
       "  'dir': <function dir>,\n",
       "  'divmod': <function divmod(x, y, /)>,\n",
       "  'eval': <function eval(source, globals=None, locals=None, /)>,\n",
       "  'exec': <function exec(source, globals=None, locals=None, /, *, closure=None)>,\n",
       "  'format': <function format(value, format_spec='', /)>,\n",
       "  'getattr': <function getattr>,\n",
       "  'globals': <function globals()>,\n",
       "  'hasattr': <function hasattr(obj, name, /)>,\n",
       "  'hash': <function hash(obj, /)>,\n",
       "  'hex': <function hex(number, /)>,\n",
       "  'id': <function id(obj, /)>,\n",
       "  'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7e55e46762a0>>,\n",
       "  'isinstance': <function isinstance(obj, class_or_tuple, /)>,\n",
       "  'issubclass': <function issubclass(cls, class_or_tuple, /)>,\n",
       "  'iter': <function iter>,\n",
       "  'aiter': <function aiter(async_iterable, /)>,\n",
       "  'len': <function len(obj, /)>,\n",
       "  'locals': <function locals()>,\n",
       "  'max': <function max>,\n",
       "  'min': <function min>,\n",
       "  'next': <function next>,\n",
       "  'anext': <function anext>,\n",
       "  'oct': <function oct(number, /)>,\n",
       "  'ord': <function ord(c, /)>,\n",
       "  'pow': <function pow(base, exp, mod=None)>,\n",
       "  'print': <function print(*args, sep=' ', end='\\n', file=None, flush=False)>,\n",
       "  'repr': <function repr(obj, /)>,\n",
       "  'round': <function round(number, ndigits=None)>,\n",
       "  'setattr': <function setattr(obj, name, value, /)>,\n",
       "  'sorted': <function sorted(iterable, /, *, key=None, reverse=False)>,\n",
       "  'sum': <function sum(iterable, /, start=0)>,\n",
       "  'vars': <function vars>,\n",
       "  'None': None,\n",
       "  'Ellipsis': Ellipsis,\n",
       "  'NotImplemented': NotImplemented,\n",
       "  'False': False,\n",
       "  'True': True,\n",
       "  'bool': bool,\n",
       "  'memoryview': memoryview,\n",
       "  'bytearray': bytearray,\n",
       "  'bytes': bytes,\n",
       "  'classmethod': classmethod,\n",
       "  'complex': complex,\n",
       "  'dict': dict,\n",
       "  'enumerate': enumerate,\n",
       "  'filter': filter,\n",
       "  'float': float,\n",
       "  'frozenset': frozenset,\n",
       "  'property': property,\n",
       "  'int': int,\n",
       "  'list': list,\n",
       "  'map': map,\n",
       "  'object': object,\n",
       "  'range': range,\n",
       "  'reversed': reversed,\n",
       "  'set': set,\n",
       "  'slice': slice,\n",
       "  'staticmethod': staticmethod,\n",
       "  'str': str,\n",
       "  'super': super,\n",
       "  'tuple': tuple,\n",
       "  'type': type,\n",
       "  'zip': zip,\n",
       "  '__debug__': True,\n",
       "  'BaseException': BaseException,\n",
       "  'BaseExceptionGroup': BaseExceptionGroup,\n",
       "  'Exception': Exception,\n",
       "  'GeneratorExit': GeneratorExit,\n",
       "  'KeyboardInterrupt': KeyboardInterrupt,\n",
       "  'SystemExit': SystemExit,\n",
       "  'ArithmeticError': ArithmeticError,\n",
       "  'AssertionError': AssertionError,\n",
       "  'AttributeError': AttributeError,\n",
       "  'BufferError': BufferError,\n",
       "  'EOFError': EOFError,\n",
       "  'ImportError': ImportError,\n",
       "  'LookupError': LookupError,\n",
       "  'MemoryError': MemoryError,\n",
       "  'NameError': NameError,\n",
       "  'OSError': OSError,\n",
       "  'ReferenceError': ReferenceError,\n",
       "  'RuntimeError': RuntimeError,\n",
       "  'StopAsyncIteration': StopAsyncIteration,\n",
       "  'StopIteration': StopIteration,\n",
       "  'SyntaxError': SyntaxError,\n",
       "  'SystemError': SystemError,\n",
       "  'TypeError': TypeError,\n",
       "  'ValueError': ValueError,\n",
       "  'Warning': Warning,\n",
       "  'FloatingPointError': FloatingPointError,\n",
       "  'OverflowError': OverflowError,\n",
       "  'ZeroDivisionError': ZeroDivisionError,\n",
       "  'BytesWarning': BytesWarning,\n",
       "  'DeprecationWarning': DeprecationWarning,\n",
       "  'EncodingWarning': EncodingWarning,\n",
       "  'FutureWarning': FutureWarning,\n",
       "  'ImportWarning': ImportWarning,\n",
       "  'PendingDeprecationWarning': PendingDeprecationWarning,\n",
       "  'ResourceWarning': ResourceWarning,\n",
       "  'RuntimeWarning': RuntimeWarning,\n",
       "  'SyntaxWarning': SyntaxWarning,\n",
       "  'UnicodeWarning': UnicodeWarning,\n",
       "  'UserWarning': UserWarning,\n",
       "  'BlockingIOError': BlockingIOError,\n",
       "  'ChildProcessError': ChildProcessError,\n",
       "  'ConnectionError': ConnectionError,\n",
       "  'FileExistsError': FileExistsError,\n",
       "  'FileNotFoundError': FileNotFoundError,\n",
       "  'InterruptedError': InterruptedError,\n",
       "  'IsADirectoryError': IsADirectoryError,\n",
       "  'NotADirectoryError': NotADirectoryError,\n",
       "  'PermissionError': PermissionError,\n",
       "  'ProcessLookupError': ProcessLookupError,\n",
       "  'TimeoutError': TimeoutError,\n",
       "  'IndentationError': IndentationError,\n",
       "  'IndexError': IndexError,\n",
       "  'KeyError': KeyError,\n",
       "  'ModuleNotFoundError': ModuleNotFoundError,\n",
       "  'NotImplementedError': NotImplementedError,\n",
       "  'RecursionError': RecursionError,\n",
       "  'UnboundLocalError': UnboundLocalError,\n",
       "  'UnicodeError': UnicodeError,\n",
       "  'BrokenPipeError': BrokenPipeError,\n",
       "  'ConnectionAbortedError': ConnectionAbortedError,\n",
       "  'ConnectionRefusedError': ConnectionRefusedError,\n",
       "  'ConnectionResetError': ConnectionResetError,\n",
       "  'TabError': TabError,\n",
       "  'UnicodeDecodeError': UnicodeDecodeError,\n",
       "  'UnicodeEncodeError': UnicodeEncodeError,\n",
       "  'UnicodeTranslateError': UnicodeTranslateError,\n",
       "  'ExceptionGroup': ExceptionGroup,\n",
       "  'EnvironmentError': OSError,\n",
       "  'IOError': OSError,\n",
       "  'open': <function _io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
       "  'copyright': Copyright (c) 2001-2023 Python Software Foundation.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 2000 BeOpen.com.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
       "  All Rights Reserved.,\n",
       "  'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
       "      for supporting Python development.  See www.python.org for more information.,\n",
       "  'license': Type license() to see the full license text,\n",
       "  'help': Type help() for interactive help, or help(object) for help about object.,\n",
       "  'execfile': <function _pydev_bundle._pydev_execfile.execfile(file, glob=None, loc=None)>,\n",
       "  'runfile': <function _pydev_bundle.pydev_umd.runfile(filename, args=None, wdir=None, namespace=None)>,\n",
       "  '__IPYTHON__': True,\n",
       "  'display': <function IPython.core.display_functions.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, raw=False, clear=False, **kwargs)>,\n",
       "  'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7e55e4676600>>},\n",
       " '__annotations__': {'__version__': str},\n",
       " 'contextlib': <module 'contextlib' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/contextlib.py'>,\n",
       " 'os': <module 'os' (frozen)>,\n",
       " '_cpu_check': <module 'polars._cpu_check' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/_cpu_check.py'>,\n",
       " 'polars': <module 'polars.polars' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/polars.abi3.so'>,\n",
       " '__register_startup_deps': <function __register_startup_deps()>,\n",
       " 'dependencies': <module 'polars.dependencies' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/dependencies.py'>,\n",
       " 'type_aliases': <module 'polars.type_aliases' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/type_aliases.py'>,\n",
       " 'datatypes': <module 'polars.datatypes' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/datatypes/__init__.py'>,\n",
       " '_utils': <module 'polars._utils' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/_utils/__init__.py'>,\n",
       " 'exceptions': <module 'polars.exceptions' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/exceptions.py'>,\n",
       " 'functions': <module 'polars.functions' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/functions/__init__.py'>,\n",
       " 'meta': <module 'polars.meta' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/meta/__init__.py'>,\n",
       " 'slice': <module 'polars.slice' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/slice.py'>,\n",
       " 'expr': <module 'polars.expr' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/expr/__init__.py'>,\n",
       " 'selectors': <module 'polars.selectors' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/selectors.py'>,\n",
       " 'dataframe': <module 'polars.dataframe' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/dataframe/__init__.py'>,\n",
       " 'lazyframe': <module 'polars.lazyframe' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/lazyframe/__init__.py'>,\n",
       " 'series': <module 'polars.series' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/series/__init__.py'>,\n",
       " '_reexport': <module 'polars._reexport' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/_reexport.py'>,\n",
       " 'api': <module 'polars.api' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/api.py'>,\n",
       " 'plugins': <module 'polars.plugins' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/plugins.py'>,\n",
       " 'wrap_df': <function polars._utils.wrap.wrap_df(df: 'PyDataFrame') -> 'DataFrame'>,\n",
       " 'wrap_s': <function polars._utils.wrap.wrap_s(s: 'PySeries') -> 'Series'>,\n",
       " 'config': <module 'polars.config' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/config.py'>,\n",
       " 'Config': polars.config.Config,\n",
       " 'convert': <module 'polars.convert' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/convert.py'>,\n",
       " 'from_arrow': <function polars.convert.from_arrow(data: 'pa.Table | pa.Array | pa.ChunkedArray | pa.RecordBatch | Iterable[pa.RecordBatch | pa.Table]', schema: 'SchemaDefinition | None' = None, *, schema_overrides: 'SchemaDict | None' = None, rechunk: 'bool' = True) -> 'DataFrame | Series'>,\n",
       " 'from_dataframe': <function polars.convert.from_dataframe(df: 'SupportsInterchange', *, allow_copy: 'bool' = True) -> 'DataFrame'>,\n",
       " 'from_dict': <function polars.convert.from_dict(data: 'Mapping[str, Sequence[object] | Mapping[str, Sequence[object]] | Series]', schema: 'SchemaDefinition | None' = None, *, schema_overrides: 'SchemaDict | None' = None, strict: 'bool' = True) -> 'DataFrame'>,\n",
       " 'from_dicts': <function polars.convert.from_dicts(data: 'Sequence[dict[str, Any]]', schema: 'SchemaDefinition | None' = None, *, schema_overrides: 'SchemaDict | None' = None, strict: 'bool' = True, infer_schema_length: 'int | None' = 100) -> 'DataFrame'>,\n",
       " 'from_numpy': <function polars.convert.from_numpy(data: 'np.ndarray[Any, Any]', schema: 'SchemaDefinition | None' = None, *, schema_overrides: 'SchemaDict | None' = None, orient: 'Orientation | None' = None) -> 'DataFrame'>,\n",
       " 'from_pandas': <function polars.convert.from_pandas(data: 'pd.DataFrame | pd.Series[Any] | pd.Index[Any] | pd.DatetimeIndex', *, schema_overrides: 'SchemaDict | None' = None, rechunk: 'bool' = True, nan_to_null: 'bool' = True, include_index: 'bool' = False) -> 'DataFrame | Series'>,\n",
       " 'from_records': <function polars.convert.from_records(data: 'Sequence[Any]', schema: 'SchemaDefinition | None' = None, *, schema_overrides: 'SchemaDict | None' = None, strict: 'bool' = True, orient: 'Orientation | None' = None, infer_schema_length: 'int | None' = 100) -> 'DataFrame'>,\n",
       " 'from_repr': <function polars.convert.from_repr(data: 'str') -> 'DataFrame | Series'>,\n",
       " 'DataFrame': polars.dataframe.frame.DataFrame,\n",
       " 'DATETIME_DTYPES': frozenset({Datetime,\n",
       "            Datetime(time_unit='ms', time_zone='*'),\n",
       "            Datetime(time_unit='ms', time_zone=None),\n",
       "            Datetime(time_unit='ns', time_zone='*'),\n",
       "            Datetime(time_unit='ns', time_zone=None),\n",
       "            Datetime(time_unit='us', time_zone='*'),\n",
       "            Datetime(time_unit='us', time_zone=None)}),\n",
       " 'DURATION_DTYPES': frozenset({Duration,\n",
       "            Duration(time_unit='ms'),\n",
       "            Duration(time_unit='ns'),\n",
       "            Duration(time_unit='us')}),\n",
       " 'FLOAT_DTYPES': frozenset({Float32, Float64}),\n",
       " 'INTEGER_DTYPES': frozenset({Int16,\n",
       "            Int32,\n",
       "            Int64,\n",
       "            Int8,\n",
       "            UInt16,\n",
       "            UInt32,\n",
       "            UInt64,\n",
       "            UInt8}),\n",
       " 'NESTED_DTYPES': frozenset({Array, List, Struct}),\n",
       " 'NUMERIC_DTYPES': frozenset({Decimal,\n",
       "            Float32,\n",
       "            Float64,\n",
       "            Int16,\n",
       "            Int32,\n",
       "            Int64,\n",
       "            Int8,\n",
       "            UInt16,\n",
       "            UInt32,\n",
       "            UInt64,\n",
       "            UInt8}),\n",
       " 'TEMPORAL_DTYPES': frozenset({Date,\n",
       "            Datetime,\n",
       "            Datetime(time_unit='ms', time_zone='*'),\n",
       "            Datetime(time_unit='ms', time_zone=None),\n",
       "            Datetime(time_unit='ns', time_zone='*'),\n",
       "            Datetime(time_unit='ns', time_zone=None),\n",
       "            Datetime(time_unit='us', time_zone='*'),\n",
       "            Datetime(time_unit='us', time_zone=None),\n",
       "            Duration,\n",
       "            Duration(time_unit='ms'),\n",
       "            Duration(time_unit='ns'),\n",
       "            Duration(time_unit='us'),\n",
       "            Time}),\n",
       " 'Array': Array,\n",
       " 'Binary': Binary,\n",
       " 'Boolean': Boolean,\n",
       " 'Categorical': Categorical,\n",
       " 'DataType': DataType,\n",
       " 'Date': Date,\n",
       " 'Datetime': Datetime,\n",
       " 'Decimal': Decimal,\n",
       " 'Duration': Duration,\n",
       " 'Enum': Enum,\n",
       " 'Field': polars.datatypes.classes.Field,\n",
       " 'Float32': Float32,\n",
       " 'Float64': Float64,\n",
       " 'Int8': Int8,\n",
       " 'Int16': Int16,\n",
       " 'Int32': Int32,\n",
       " 'Int64': Int64,\n",
       " 'List': List,\n",
       " 'Null': Null,\n",
       " 'Object': Object,\n",
       " 'String': String,\n",
       " 'Struct': Struct,\n",
       " 'Time': Time,\n",
       " 'UInt8': UInt8,\n",
       " 'UInt16': UInt16,\n",
       " 'UInt32': UInt32,\n",
       " 'UInt64': UInt64,\n",
       " 'Unknown': Unknown,\n",
       " 'Utf8': String,\n",
       " 'ArrowError': polars.exceptions.ArrowError,\n",
       " 'CategoricalRemappingWarning': polars.exceptions.CategoricalRemappingWarning,\n",
       " 'ChronoFormatWarning': polars.exceptions.ChronoFormatWarning,\n",
       " 'ColumnNotFoundError': polars.exceptions.ColumnNotFoundError,\n",
       " 'ComputeError': polars.exceptions.ComputeError,\n",
       " 'DuplicateError': polars.exceptions.DuplicateError,\n",
       " 'InvalidOperationError': polars.exceptions.InvalidOperationError,\n",
       " 'MapWithoutReturnDtypeWarning': polars.exceptions.MapWithoutReturnDtypeWarning,\n",
       " 'NoDataError': polars.exceptions.NoDataError,\n",
       " 'OutOfBoundsError': polars.exceptions.OutOfBoundsError,\n",
       " 'PolarsError': polars.exceptions.PolarsBaseError,\n",
       " 'PolarsPanicError': pyo3_runtime.PanicException,\n",
       " 'PolarsWarning': polars.exceptions.PolarsBaseWarning,\n",
       " 'SchemaError': polars.exceptions.SchemaError,\n",
       " 'SchemaFieldNotFoundError': polars.exceptions.SchemaFieldNotFoundError,\n",
       " 'ShapeError': polars.exceptions.ShapeError,\n",
       " 'StructFieldNotFoundError': polars.exceptions.StructFieldNotFoundError,\n",
       " 'UnstableWarning': polars.exceptions.UnstableWarning,\n",
       " 'Expr': polars.expr.expr.Expr,\n",
       " 'align_frames': <function polars.functions.eager.align_frames(*frames: 'FrameType', on: 'str | Expr | Sequence[str] | Sequence[Expr] | Sequence[str | Expr]', how: 'JoinStrategy' = 'full', select: 'str | Expr | Sequence[str | Expr] | None' = None, descending: 'bool | Sequence[bool]' = False) -> 'list[FrameType]'>,\n",
       " 'all': <function polars.functions.aggregation.vertical.all(*names: 'str', ignore_nulls: 'bool' = True) -> 'Expr'>,\n",
       " 'all_horizontal': <function polars.functions.aggregation.horizontal.all_horizontal(*exprs: 'IntoExpr | Iterable[IntoExpr]') -> 'Expr'>,\n",
       " 'any': <function polars.functions.aggregation.vertical.any(*names: 'str', ignore_nulls: 'bool' = True) -> 'Expr | bool | None'>,\n",
       " 'any_horizontal': <function polars.functions.aggregation.horizontal.any_horizontal(*exprs: 'IntoExpr | Iterable[IntoExpr]') -> 'Expr'>,\n",
       " 'apply': <function polars.functions.lazy.apply(exprs: 'Sequence[str | Expr]', function: 'Callable[[Sequence[Series]], Series | Any]', return_dtype: 'PolarsDataType | None' = None, *, returns_scalar: 'bool' = True) -> 'Expr'>,\n",
       " 'approx_n_unique': <function polars.functions.lazy.approx_n_unique(*columns: 'str') -> 'Expr'>,\n",
       " 'arange': <function polars.functions.range.int_range.arange(start: 'int | IntoExprColumn' = 0, end: 'int | IntoExprColumn | None' = None, step: 'int' = 1, *, dtype: 'PolarsIntegerType' = Int64, eager: 'bool' = False) -> 'Expr | Series'>,\n",
       " 'arctan2': <function polars.functions.lazy.arctan2(y: 'str | Expr', x: 'str | Expr') -> 'Expr'>,\n",
       " 'arctan2d': <function polars.functions.lazy.arctan2d(y: 'str | Expr', x: 'str | Expr') -> 'Expr'>,\n",
       " 'arg_sort_by': <function polars.functions.lazy.arg_sort_by(exprs: 'IntoExpr | Iterable[IntoExpr]', *more_exprs: 'IntoExpr', descending: 'bool | Sequence[bool]' = False, nulls_last: 'bool | Sequence[bool]' = False, multithreaded: 'bool' = True, maintain_order: 'bool' = False) -> 'Expr'>,\n",
       " 'arg_where': <function polars.functions.lazy.arg_where(condition: 'Expr | Series', *, eager: 'bool' = False) -> 'Expr | Series'>,\n",
       " 'business_day_count': <function polars.functions.business.business_day_count(start: 'date | IntoExprColumn', end: 'date | IntoExprColumn', week_mask: 'Iterable[bool]' = (True, True, True, True, True, False, False), holidays: 'Iterable[date]' = ()) -> 'Expr'>,\n",
       " 'coalesce': <function polars.functions.lazy.coalesce(exprs: 'IntoExpr | Iterable[IntoExpr]', *more_exprs: 'IntoExpr') -> 'Expr'>,\n",
       " 'col': polars.functions.col.ColumnFactory,\n",
       " 'collect_all': <function polars.functions.lazy.collect_all(lazy_frames: 'Iterable[LazyFrame]', *, type_coercion: 'bool' = True, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, simplify_expression: 'bool' = True, no_optimization: 'bool' = False, slice_pushdown: 'bool' = True, comm_subplan_elim: 'bool' = True, comm_subexpr_elim: 'bool' = True, cluster_with_columns: 'bool' = True, streaming: 'bool' = False) -> 'list[DataFrame]'>,\n",
       " 'collect_all_async': <function polars.functions.lazy.collect_all_async(lazy_frames: 'Iterable[LazyFrame]', *, gevent: 'bool' = False, type_coercion: 'bool' = True, predicate_pushdown: 'bool' = True, projection_pushdown: 'bool' = True, simplify_expression: 'bool' = True, no_optimization: 'bool' = False, slice_pushdown: 'bool' = True, comm_subplan_elim: 'bool' = True, comm_subexpr_elim: 'bool' = True, cluster_with_columns: 'bool' = True, streaming: 'bool' = False) -> 'Awaitable[list[DataFrame]] | _GeventDataFrameResult[list[DataFrame]]'>,\n",
       " 'concat': <function polars.functions.eager.concat(items: 'Iterable[PolarsType]', *, how: 'ConcatMethod' = 'vertical', rechunk: 'bool' = False, parallel: 'bool' = True) -> 'PolarsType'>,\n",
       " 'concat_list': <function polars.functions.as_datatype.concat_list(exprs: 'IntoExpr | Iterable[IntoExpr]', *more_exprs: 'IntoExpr') -> 'Expr'>,\n",
       " 'concat_str': <function polars.functions.as_datatype.concat_str(exprs: 'IntoExpr | Iterable[IntoExpr]', *more_exprs: 'IntoExpr', separator: 'str' = '', ignore_nulls: 'bool' = False) -> 'Expr'>,\n",
       " 'corr': <function polars.functions.lazy.corr(a: 'IntoExpr', b: 'IntoExpr', *, method: 'CorrelationMethod' = 'pearson', ddof: 'int' = 1, propagate_nans: 'bool' = False) -> 'Expr'>,\n",
       " 'count': <function polars.functions.lazy.count(*columns: 'str') -> 'Expr'>,\n",
       " 'cov': <function polars.functions.lazy.cov(a: 'IntoExpr', b: 'IntoExpr', ddof: 'int' = 1) -> 'Expr'>,\n",
       " 'cum_count': <function polars.functions.lazy.cum_count(*columns: 'str', reverse: 'bool' = False) -> 'Expr'>,\n",
       " 'cum_fold': <function polars.functions.lazy.cum_fold(acc: 'IntoExpr', function: 'Callable[[Series, Series], Series]', exprs: 'Sequence[Expr | str] | Expr', *, include_init: 'bool' = False) -> 'Expr'>,\n",
       " 'cum_reduce': <function polars.functions.lazy.cum_reduce(function: 'Callable[[Series, Series], Series]', exprs: 'Sequence[Expr | str] | Expr') -> 'Expr'>,\n",
       " 'cum_sum': <function polars.functions.aggregation.vertical.cum_sum(*names: 'str') -> 'Expr'>,\n",
       " 'cum_sum_horizontal': <function polars.functions.aggregation.horizontal.cum_sum_horizontal(*exprs: 'IntoExpr | Iterable[IntoExpr]') -> 'Expr'>,\n",
       " 'cumfold': <function polars.functions.lazy.cumfold(acc: 'IntoExpr', function: 'Callable[[Series, Series], Series]', exprs: 'Sequence[Expr | str] | Expr', *, include_init: 'bool' = False) -> 'Expr'>,\n",
       " 'cumreduce': <function polars.functions.lazy.cumreduce(function: 'Callable[[Series, Series], Series]', exprs: 'Sequence[Expr | str] | Expr') -> 'Expr'>,\n",
       " 'cumsum': <function polars.functions.aggregation.vertical.cumsum(*names: 'str') -> 'Expr'>,\n",
       " 'cumsum_horizontal': <function polars.functions.aggregation.horizontal.cumsum_horizontal(*exprs: 'IntoExpr | Iterable[IntoExpr]') -> 'Expr'>,\n",
       " 'date': <function polars.functions.as_datatype.date_(year: 'Expr | str | int', month: 'Expr | str | int', day: 'Expr | str | int') -> 'Expr'>,\n",
       " 'date_range': <function polars.functions.range.date_range.date_range(start: 'date | datetime | IntoExprColumn', end: 'date | datetime | IntoExprColumn', interval: 'str | timedelta' = '1d', *, closed: 'ClosedInterval' = 'both', time_unit: 'TimeUnit | None' = None, time_zone: 'str | None' = None, eager: 'bool' = False) -> 'Series | Expr'>,\n",
       " 'date_ranges': <function polars.functions.range.date_range.date_ranges(start: 'date | datetime | IntoExprColumn', end: 'date | datetime | IntoExprColumn', interval: 'str | timedelta' = '1d', *, closed: 'ClosedInterval' = 'both', time_unit: 'TimeUnit | None' = None, time_zone: 'str | None' = None, eager: 'bool' = False) -> 'Series | Expr'>,\n",
       " 'datetime': <function polars.functions.as_datatype.datetime_(year: 'int | IntoExpr', month: 'int | IntoExpr', day: 'int | IntoExpr', hour: 'int | IntoExpr | None' = None, minute: 'int | IntoExpr | None' = None, second: 'int | IntoExpr | None' = None, microsecond: 'int | IntoExpr | None' = None, *, time_unit: 'TimeUnit' = 'us', time_zone: 'str | None' = None, use_earliest: 'bool | None' = None, ambiguous: 'Ambiguous | Expr' = 'raise') -> 'Expr'>,\n",
       " 'datetime_range': <function polars.functions.range.datetime_range.datetime_range(start: 'datetime | date | IntoExprColumn', end: 'datetime | date | IntoExprColumn', interval: 'str | timedelta' = '1d', *, closed: 'ClosedInterval' = 'both', time_unit: 'TimeUnit | None' = None, time_zone: 'str | None' = None, eager: 'bool' = False) -> 'Series | Expr'>,\n",
       " 'datetime_ranges': <function polars.functions.range.datetime_range.datetime_ranges(start: 'datetime | date | IntoExprColumn', end: 'datetime | date | IntoExprColumn', interval: 'str | timedelta' = '1d', *, closed: 'ClosedInterval' = 'both', time_unit: 'TimeUnit | None' = None, time_zone: 'str | None' = None, eager: 'bool' = False) -> 'Series | Expr'>,\n",
       " 'duration': <function polars.functions.as_datatype.duration(*, weeks: 'Expr | str | int | None' = None, days: 'Expr | str | int | None' = None, hours: 'Expr | str | int | None' = None, minutes: 'Expr | str | int | None' = None, seconds: 'Expr | str | int | None' = None, milliseconds: 'Expr | str | int | None' = None, microseconds: 'Expr | str | int | None' = None, nanoseconds: 'Expr | str | int | None' = None, time_unit: 'TimeUnit | None' = None) -> 'Expr'>,\n",
       " 'element': <function polars.functions.lazy.element() -> 'Expr'>,\n",
       " 'exclude': <function polars.functions.lazy.exclude(columns: 'str | PolarsDataType | Collection[str] | Collection[PolarsDataType]', *more_columns: 'str | PolarsDataType') -> 'Expr'>,\n",
       " 'field': <function polars.functions.lazy.field(name: 'str | list[str]') -> 'Expr'>,\n",
       " 'first': <function polars.functions.lazy.first(*columns: 'str') -> 'Expr'>,\n",
       " 'fold': <function polars.functions.lazy.fold(acc: 'IntoExpr', function: 'Callable[[Series, Series], Series]', exprs: 'Sequence[Expr | str] | Expr') -> 'Expr'>,\n",
       " 'format': <function polars.functions.as_datatype.format(f_string: 'str', *args: 'Expr | str') -> 'Expr'>,\n",
       " 'from_epoch': <function polars.functions.lazy.from_epoch(column: 'str | Expr | Series | Sequence[int]', time_unit: 'EpochTimeUnit' = 's') -> 'Expr | Series'>,\n",
       " 'groups': <function polars.functions.lazy.groups(column: 'str') -> 'Expr'>,\n",
       " 'head': <function polars.functions.lazy.head(column: 'str', n: 'int' = 10) -> 'Expr'>,\n",
       " 'implode': <function polars.functions.lazy.implode(*columns: 'str') -> 'Expr'>,\n",
       " 'int_range': <function polars.functions.range.int_range.int_range(start: 'int | IntoExprColumn' = 0, end: 'int | IntoExprColumn | None' = None, step: 'int' = 1, *, dtype: 'PolarsIntegerType' = Int64, eager: 'bool' = False) -> 'Expr | Series'>,\n",
       " 'int_ranges': <function polars.functions.range.int_range.int_ranges(start: 'int | IntoExprColumn' = 0, end: 'int | IntoExprColumn | None' = None, step: 'int | IntoExprColumn' = 1, *, dtype: 'PolarsIntegerType' = Int64, eager: 'bool' = False) -> 'Expr | Series'>,\n",
       " 'last': <function polars.functions.lazy.last(*columns: 'str') -> 'Expr'>,\n",
       " 'len': <function polars.functions.len.len() -> 'Expr'>,\n",
       " 'lit': <function polars.functions.lit.lit(value: 'Any', dtype: 'PolarsDataType | None' = None, *, allow_object: 'bool' = False) -> 'Expr'>,\n",
       " 'map': <function polars.functions.lazy.map(exprs: 'Sequence[str] | Sequence[Expr]', function: 'Callable[[Sequence[Series]], Series]', return_dtype: 'PolarsDataType | None' = None) -> 'Expr'>,\n",
       " 'map_batches': <function polars.functions.lazy.map_batches(exprs: 'Sequence[str] | Sequence[Expr]', function: 'Callable[[Sequence[Series]], Series]', return_dtype: 'PolarsDataType | None' = None) -> 'Expr'>,\n",
       " 'map_groups': <function polars.functions.lazy.map_groups(exprs: 'Sequence[str | Expr]', function: 'Callable[[Sequence[Series]], Series | Any]', return_dtype: 'PolarsDataType | None' = None, *, returns_scalar: 'bool' = True) -> 'Expr'>,\n",
       " 'max': <function polars.functions.aggregation.vertical.max(*names: 'str') -> 'Expr'>,\n",
       " 'max_horizontal': <function polars.functions.aggregation.horizontal.max_horizontal(*exprs: 'IntoExpr | Iterable[IntoExpr]') -> 'Expr'>,\n",
       " 'mean': <function polars.functions.lazy.mean(*columns: 'str') -> 'Expr'>,\n",
       " 'mean_horizontal': <function polars.functions.aggregation.horizontal.mean_horizontal(*exprs: 'IntoExpr | Iterable[IntoExpr]') -> 'Expr'>,\n",
       " 'median': <function polars.functions.lazy.median(*columns: 'str') -> 'Expr'>,\n",
       " 'min': <function polars.functions.aggregation.vertical.min(*names: 'str') -> 'Expr'>,\n",
       " 'min_horizontal': <function polars.functions.aggregation.horizontal.min_horizontal(*exprs: 'IntoExpr | Iterable[IntoExpr]') -> 'Expr'>,\n",
       " 'n_unique': <function polars.functions.lazy.n_unique(*columns: 'str') -> 'Expr'>,\n",
       " 'nth': <function polars.functions.lazy.nth(n: 'int | Sequence[int]', *columns: 'str') -> 'Expr'>,\n",
       " 'ones': <function polars.functions.repeat.ones(n: 'int | Expr', dtype: 'PolarsDataType' = Float64, *, eager: 'bool' = False) -> 'Expr | Series'>,\n",
       " 'quantile': <function polars.functions.lazy.quantile(column: 'str', quantile: 'float | Expr', interpolation: 'RollingInterpolationMethod' = 'nearest') -> 'Expr'>,\n",
       " 'reduce': <function polars.functions.lazy.reduce(function: 'Callable[[Series, Series], Series]', exprs: 'Sequence[Expr | str] | Expr') -> 'Expr'>,\n",
       " 'repeat': <function polars.functions.repeat.repeat(value: 'IntoExpr | None', n: 'int | Expr', *, dtype: 'PolarsDataType | None' = None, eager: 'bool' = False) -> 'Expr | Series'>,\n",
       " 'rolling_corr': <function polars.functions.lazy.rolling_corr(a: 'str | Expr', b: 'str | Expr', *, window_size: 'int', min_periods: 'int | None' = None, ddof: 'int' = 1) -> 'Expr'>,\n",
       " 'rolling_cov': <function polars.functions.lazy.rolling_cov(a: 'str | Expr', b: 'str | Expr', *, window_size: 'int', min_periods: 'int | None' = None, ddof: 'int' = 1) -> 'Expr'>,\n",
       " 'select': <function polars.functions.lazy.select(*exprs: 'IntoExpr | Iterable[IntoExpr]', **named_exprs: 'IntoExpr') -> 'DataFrame'>,\n",
       " 'set_random_seed': <function polars.functions.random.set_random_seed(seed: 'int') -> 'None'>,\n",
       " 'sql_expr': <function polars.functions.lazy.sql_expr(sql: 'str | Sequence[str]') -> 'Expr | list[Expr]'>,\n",
       " 'std': <function polars.functions.lazy.std(column: 'str', ddof: 'int' = 1) -> 'Expr'>,\n",
       " 'struct': <function polars.functions.as_datatype.struct(*exprs: 'IntoExpr | Iterable[IntoExpr]', schema: 'SchemaDict | None' = None, eager: 'bool' = False, **named_exprs: 'IntoExpr') -> 'Expr | Series'>,\n",
       " 'sum': <function polars.functions.aggregation.vertical.sum(*names: 'str') -> 'Expr'>,\n",
       " 'sum_horizontal': <function polars.functions.aggregation.horizontal.sum_horizontal(*exprs: 'IntoExpr | Iterable[IntoExpr]') -> 'Expr'>,\n",
       " 'tail': <function polars.functions.lazy.tail(column: 'str', n: 'int' = 10) -> 'Expr'>,\n",
       " 'time': <function polars.functions.as_datatype.time_(hour: 'Expr | str | int | None' = None, minute: 'Expr | str | int | None' = None, second: 'Expr | str | int | None' = None, microsecond: 'Expr | str | int | None' = None) -> 'Expr'>,\n",
       " 'time_range': <function polars.functions.range.time_range.time_range(start: 'time | IntoExprColumn | None' = None, end: 'time | IntoExprColumn | None' = None, interval: 'str | timedelta' = '1h', *, closed: 'ClosedInterval' = 'both', eager: 'bool' = False) -> 'Series | Expr'>,\n",
       " 'time_ranges': <function polars.functions.range.time_range.time_ranges(start: 'time | IntoExprColumn | None' = None, end: 'time | IntoExprColumn | None' = None, interval: 'str | timedelta' = '1h', *, closed: 'ClosedInterval' = 'both', eager: 'bool' = False) -> 'Series | Expr'>,\n",
       " 'var': <function polars.functions.lazy.var(column: 'str', ddof: 'int' = 1) -> 'Expr'>,\n",
       " 'when': <function polars.functions.whenthen.when(*predicates: 'IntoExprColumn | Iterable[IntoExprColumn] | bool', **constraints: 'Any') -> 'pl.When'>,\n",
       " 'zeros': <function polars.functions.repeat.zeros(n: 'int | Expr', dtype: 'PolarsDataType' = Float64, *, eager: 'bool' = False) -> 'Expr | Series'>,\n",
       " 'io': <module 'polars.io' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/io/__init__.py'>,\n",
       " 'read_avro': <function polars.io.avro.read_avro(source: 'str | Path | IO[bytes] | bytes', *, columns: 'list[int] | list[str] | None' = None, n_rows: 'int | None' = None) -> 'DataFrame'>,\n",
       " 'read_clipboard': <function polars.io.clipboard.read_clipboard(separator: 'str' = '\\t', **kwargs: 'Any') -> 'DataFrame'>,\n",
       " 'read_csv': <function polars.io.csv.functions.read_csv(source: 'str | Path | IO[str] | IO[bytes] | bytes', *, has_header: 'bool' = True, columns: 'Sequence[int] | Sequence[str] | None' = None, new_columns: 'Sequence[str] | None' = None, separator: 'str' = ',', comment_prefix: 'str | None' = None, quote_char: 'str | None' = '\"', skip_rows: 'int' = 0, schema: 'SchemaDict | None' = None, schema_overrides: 'Mapping[str, PolarsDataType] | Sequence[PolarsDataType] | None' = None, null_values: 'str | Sequence[str] | dict[str, str] | None' = None, missing_utf8_is_empty_string: 'bool' = False, ignore_errors: 'bool' = False, try_parse_dates: 'bool' = False, n_threads: 'int | None' = None, infer_schema_length: 'int | None' = 100, batch_size: 'int' = 8192, n_rows: 'int | None' = None, encoding: 'CsvEncoding | str' = 'utf8', low_memory: 'bool' = False, rechunk: 'bool' = False, use_pyarrow: 'bool' = False, storage_options: 'dict[str, Any] | None' = None, skip_rows_after_header: 'int' = 0, row_index_name: 'str | None' = None, row_index_offset: 'int' = 0, sample_size: 'int' = 1024, eol_char: 'str' = '\\n', raise_if_empty: 'bool' = True, truncate_ragged_lines: 'bool' = False, decimal_comma: 'bool' = False, glob: 'bool' = True) -> 'DataFrame'>,\n",
       " 'read_csv_batched': <function polars.io.csv.functions.read_csv_batched(source: 'str | Path', *, has_header: 'bool' = True, columns: 'Sequence[int] | Sequence[str] | None' = None, new_columns: 'Sequence[str] | None' = None, separator: 'str' = ',', comment_prefix: 'str | None' = None, quote_char: 'str | None' = '\"', skip_rows: 'int' = 0, schema_overrides: 'Mapping[str, PolarsDataType] | Sequence[PolarsDataType] | None' = None, null_values: 'str | Sequence[str] | dict[str, str] | None' = None, missing_utf8_is_empty_string: 'bool' = False, ignore_errors: 'bool' = False, try_parse_dates: 'bool' = False, n_threads: 'int | None' = None, infer_schema_length: 'int | None' = 100, batch_size: 'int' = 50000, n_rows: 'int | None' = None, encoding: 'CsvEncoding | str' = 'utf8', low_memory: 'bool' = False, rechunk: 'bool' = False, skip_rows_after_header: 'int' = 0, row_index_name: 'str | None' = None, row_index_offset: 'int' = 0, sample_size: 'int' = 1024, eol_char: 'str' = '\\n', raise_if_empty: 'bool' = True, truncate_ragged_lines: 'bool' = False, decimal_comma: 'bool' = False) -> 'BatchedCsvReader'>,\n",
       " 'read_database': <function polars.io.database.functions.read_database(query: 'str | Selectable', connection: 'ConnectionOrCursor | str', *, iter_batches: 'bool' = False, batch_size: 'int | None' = None, schema_overrides: 'SchemaDict | None' = None, infer_schema_length: 'int | None' = 100, execute_options: 'dict[str, Any] | None' = None, **kwargs: 'Any') -> 'DataFrame | Iterable[DataFrame]'>,\n",
       " 'read_database_uri': <function polars.io.database.functions.read_database_uri(query: 'list[str] | str', uri: 'str', *, partition_on: 'str | None' = None, partition_range: 'tuple[int, int] | None' = None, partition_num: 'int | None' = None, protocol: 'str | None' = None, engine: 'DbReadEngine | None' = None, schema_overrides: 'SchemaDict | None' = None, execute_options: 'dict[str, Any] | None' = None) -> 'DataFrame'>,\n",
       " 'read_delta': <function polars.io.delta.read_delta(source: 'str', *, version: 'int | str | datetime | None' = None, columns: 'list[str] | None' = None, storage_options: 'dict[str, Any] | None' = None, delta_table_options: 'dict[str, Any] | None' = None, pyarrow_options: 'dict[str, Any] | None' = None) -> 'DataFrame'>,\n",
       " 'read_excel': <function polars.io.spreadsheet.functions.read_excel(source: 'str | Path | IO[bytes] | bytes', *, sheet_id: 'int | Sequence[int] | None' = None, sheet_name: 'str | list[str] | tuple[str] | None' = None, engine: 'ExcelSpreadsheetEngine | None' = None, engine_options: 'dict[str, Any] | None' = None, read_options: 'dict[str, Any] | None' = None, schema_overrides: 'SchemaDict | None' = None, infer_schema_length: 'int | None' = 100, raise_if_empty: 'bool' = True) -> 'pl.DataFrame | dict[str, pl.DataFrame]'>,\n",
       " 'read_ipc': <function polars.io.ipc.functions.read_ipc(source: 'str | Path | IO[bytes] | bytes', *, columns: 'list[int] | list[str] | None' = None, n_rows: 'int | None' = None, use_pyarrow: 'bool' = False, memory_map: 'bool' = True, storage_options: 'dict[str, Any] | None' = None, row_index_name: 'str | None' = None, row_index_offset: 'int' = 0, rechunk: 'bool' = True) -> 'DataFrame'>,\n",
       " 'read_ipc_schema': <function polars.io.ipc.functions.read_ipc_schema(source: 'str | Path | IO[bytes] | bytes') -> 'dict[str, DataType]'>,\n",
       " 'read_ipc_stream': <function polars.io.ipc.functions.read_ipc_stream(source: 'str | Path | IO[bytes] | bytes', *, columns: 'list[int] | list[str] | None' = None, n_rows: 'int | None' = None, use_pyarrow: 'bool' = False, storage_options: 'dict[str, Any] | None' = None, row_index_name: 'str | None' = None, row_index_offset: 'int' = 0, rechunk: 'bool' = True) -> 'DataFrame'>,\n",
       " 'read_json': <function polars.io.json.read_json(source: 'str | Path | IOBase | bytes', *, schema: 'SchemaDefinition | None' = None, schema_overrides: 'SchemaDefinition | None' = None, infer_schema_length: 'int | None' = 100) -> 'DataFrame'>,\n",
       " 'read_ndjson': <function polars.io.ndjson.read_ndjson(source: 'str | Path | IOBase | bytes', *, schema: 'SchemaDefinition | None' = None, schema_overrides: 'SchemaDefinition | None' = None, ignore_errors: 'bool' = False) -> 'DataFrame'>,\n",
       " 'read_ods': <function polars.io.spreadsheet.functions.read_ods(source: 'str | Path | IO[bytes] | bytes', *, sheet_id: 'int | Sequence[int] | None' = None, sheet_name: 'str | list[str] | tuple[str] | None' = None, schema_overrides: 'SchemaDict | None' = None, infer_schema_length: 'int | None' = 100, raise_if_empty: 'bool' = True) -> 'pl.DataFrame | dict[str, pl.DataFrame]'>,\n",
       " 'read_parquet': <function polars.io.parquet.functions.read_parquet(source: 'str | Path | list[str] | list[Path] | IO[bytes] | bytes', *, columns: 'list[int] | list[str] | None' = None, n_rows: 'int | None' = None, row_index_name: 'str | None' = None, row_index_offset: 'int' = 0, parallel: 'ParallelStrategy' = 'auto', use_statistics: 'bool' = True, hive_partitioning: 'bool' = True, glob: 'bool' = True, hive_schema: 'SchemaDict | None' = None, rechunk: 'bool' = False, low_memory: 'bool' = False, storage_options: 'dict[str, Any] | None' = None, retries: 'int' = 0, use_pyarrow: 'bool' = False, pyarrow_options: 'dict[str, Any] | None' = None, memory_map: 'bool' = True) -> 'DataFrame'>,\n",
       " 'read_parquet_schema': <function polars.io.parquet.functions.read_parquet_schema(source: 'str | Path | IO[bytes] | bytes') -> 'dict[str, DataType]'>,\n",
       " 'scan_csv': <function polars.io.csv.functions.scan_csv(source: 'str | Path | list[str] | list[Path]', *, has_header: 'bool' = True, separator: 'str' = ',', comment_prefix: 'str | None' = None, quote_char: 'str | None' = '\"', skip_rows: 'int' = 0, schema: 'SchemaDict | None' = None, schema_overrides: 'SchemaDict | Sequence[PolarsDataType] | None' = None, null_values: 'str | Sequence[str] | dict[str, str] | None' = None, missing_utf8_is_empty_string: 'bool' = False, ignore_errors: 'bool' = False, cache: 'bool' = True, with_column_names: 'Callable[[list[str]], list[str]] | None' = None, infer_schema_length: 'int | None' = 100, n_rows: 'int | None' = None, encoding: 'CsvEncoding' = 'utf8', low_memory: 'bool' = False, rechunk: 'bool' = False, skip_rows_after_header: 'int' = 0, row_index_name: 'str | None' = None, row_index_offset: 'int' = 0, try_parse_dates: 'bool' = False, eol_char: 'str' = '\\n', new_columns: 'Sequence[str] | None' = None, raise_if_empty: 'bool' = True, truncate_ragged_lines: 'bool' = False, decimal_comma: 'bool' = False, glob: 'bool' = True) -> 'LazyFrame'>,\n",
       " 'scan_delta': <function polars.io.delta.scan_delta(source: 'str', *, version: 'int | str | datetime | None' = None, storage_options: 'dict[str, Any] | None' = None, delta_table_options: 'dict[str, Any] | None' = None, pyarrow_options: 'dict[str, Any] | None' = None) -> 'LazyFrame'>,\n",
       " 'scan_iceberg': <function polars.io.iceberg.scan_iceberg(source: 'str | Table', *, storage_options: 'dict[str, Any] | None' = None) -> 'LazyFrame'>,\n",
       " 'scan_ipc': <function polars.io.ipc.functions.scan_ipc(source: 'str | Path | list[str] | list[Path]', *, n_rows: 'int | None' = None, cache: 'bool' = True, rechunk: 'bool' = False, row_index_name: 'str | None' = None, row_index_offset: 'int' = 0, storage_options: 'dict[str, Any] | None' = None, memory_map: 'bool' = True, retries: 'int' = 0) -> 'LazyFrame'>,\n",
       " 'scan_ndjson': <function polars.io.ndjson.scan_ndjson(source: 'str | Path | list[str] | list[Path]', *, schema: 'SchemaDefinition | None' = None, infer_schema_length: 'int | None' = 100, batch_size: 'int | None' = 1024, n_rows: 'int | None' = None, low_memory: 'bool' = False, rechunk: 'bool' = False, row_index_name: 'str | None' = None, row_index_offset: 'int' = 0, ignore_errors: 'bool' = False) -> 'LazyFrame'>,\n",
       " 'scan_parquet': <function polars.io.parquet.functions.scan_parquet(source: 'str | Path | list[str] | list[Path]', *, n_rows: 'int | None' = None, row_index_name: 'str | None' = None, row_index_offset: 'int' = 0, parallel: 'ParallelStrategy' = 'auto', use_statistics: 'bool' = True, hive_partitioning: 'bool' = True, glob: 'bool' = True, hive_schema: 'SchemaDict | None' = None, rechunk: 'bool' = False, low_memory: 'bool' = False, cache: 'bool' = True, storage_options: 'dict[str, Any] | None' = None, retries: 'int' = 0) -> 'LazyFrame'>,\n",
       " 'scan_pyarrow_dataset': <function polars.io.pyarrow_dataset.functions.scan_pyarrow_dataset(source: 'pa.dataset.Dataset', *, allow_pyarrow_filter: 'bool' = True, batch_size: 'int | None' = None) -> 'LazyFrame'>,\n",
       " 'InProcessQuery': polars.lazyframe.in_process.InProcessQuery,\n",
       " 'LazyFrame': polars.lazyframe.frame.LazyFrame,\n",
       " 'build_info': <function polars.meta.build.build_info() -> 'dict[str, Any]'>,\n",
       " 'get_index_type': <function polars.meta.index_type.get_index_type() -> 'DataType'>,\n",
       " 'show_versions': <function polars.meta.versions.show_versions() -> 'None'>,\n",
       " 'thread_pool_size': <function polars.meta.thread_pool.thread_pool_size() -> 'int'>,\n",
       " 'threadpool_size': <function polars.meta.thread_pool.threadpool_size() -> 'int'>,\n",
       " 'Series': polars.series.series.Series,\n",
       " 'sql': <function polars.sql.functions.sql(query: 'str', *, eager: 'bool' = False) -> 'DataFrame | LazyFrame'>,\n",
       " 'SQLContext': polars.sql.context.SQLContext,\n",
       " 'string_cache': <module 'polars.string_cache' from '/home/aamad/anaconda3/envs/geostuff/lib/python3.12/site-packages/polars/string_cache.py'>,\n",
       " 'StringCache': polars.string_cache.StringCache,\n",
       " 'disable_string_cache': <function polars.string_cache.disable_string_cache() -> 'bool'>,\n",
       " 'enable_string_cache': <function polars.string_cache.enable_string_cache(enable: 'bool | None' = None) -> 'None'>,\n",
       " 'using_string_cache': <function polars.string_cache.using_string_cache() -> 'bool'>,\n",
       " 'PolarsDataType': typing.Union[ForwardRef('DataTypeClass'), ForwardRef('DataType')],\n",
       " '__version__': '0.20.31',\n",
       " '__all__': ['api',\n",
       "  'exceptions',\n",
       "  'plugins',\n",
       "  'ArrowError',\n",
       "  'ColumnNotFoundError',\n",
       "  'ComputeError',\n",
       "  'DuplicateError',\n",
       "  'InvalidOperationError',\n",
       "  'NoDataError',\n",
       "  'OutOfBoundsError',\n",
       "  'PolarsError',\n",
       "  'PolarsPanicError',\n",
       "  'SchemaError',\n",
       "  'SchemaFieldNotFoundError',\n",
       "  'ShapeError',\n",
       "  'StructFieldNotFoundError',\n",
       "  'PolarsWarning',\n",
       "  'CategoricalRemappingWarning',\n",
       "  'ChronoFormatWarning',\n",
       "  'MapWithoutReturnDtypeWarning',\n",
       "  'UnstableWarning',\n",
       "  'DataFrame',\n",
       "  'Expr',\n",
       "  'LazyFrame',\n",
       "  'Series',\n",
       "  'InProcessQuery',\n",
       "  'Array',\n",
       "  'Binary',\n",
       "  'Boolean',\n",
       "  'Categorical',\n",
       "  'DataType',\n",
       "  'Date',\n",
       "  'Datetime',\n",
       "  'Decimal',\n",
       "  'Duration',\n",
       "  'Enum',\n",
       "  'Field',\n",
       "  'Float32',\n",
       "  'Float64',\n",
       "  'Int16',\n",
       "  'Int32',\n",
       "  'Int64',\n",
       "  'Int8',\n",
       "  'List',\n",
       "  'Null',\n",
       "  'Object',\n",
       "  'String',\n",
       "  'Struct',\n",
       "  'Time',\n",
       "  'UInt16',\n",
       "  'UInt32',\n",
       "  'UInt64',\n",
       "  'UInt8',\n",
       "  'Unknown',\n",
       "  'Utf8',\n",
       "  'DATETIME_DTYPES',\n",
       "  'DURATION_DTYPES',\n",
       "  'FLOAT_DTYPES',\n",
       "  'INTEGER_DTYPES',\n",
       "  'NESTED_DTYPES',\n",
       "  'NUMERIC_DTYPES',\n",
       "  'TEMPORAL_DTYPES',\n",
       "  'PolarsDataType',\n",
       "  'read_avro',\n",
       "  'read_clipboard',\n",
       "  'read_csv',\n",
       "  'read_csv_batched',\n",
       "  'read_database',\n",
       "  'read_database_uri',\n",
       "  'read_delta',\n",
       "  'read_excel',\n",
       "  'read_ipc',\n",
       "  'read_ipc_schema',\n",
       "  'read_ipc_stream',\n",
       "  'read_json',\n",
       "  'read_ndjson',\n",
       "  'read_ods',\n",
       "  'read_parquet',\n",
       "  'read_parquet_schema',\n",
       "  'scan_csv',\n",
       "  'scan_delta',\n",
       "  'scan_iceberg',\n",
       "  'scan_ipc',\n",
       "  'scan_ndjson',\n",
       "  'scan_parquet',\n",
       "  'scan_pyarrow_dataset',\n",
       "  'StringCache',\n",
       "  'disable_string_cache',\n",
       "  'enable_string_cache',\n",
       "  'using_string_cache',\n",
       "  'Config',\n",
       "  'when',\n",
       "  'align_frames',\n",
       "  'arg_where',\n",
       "  'business_day_count',\n",
       "  'concat',\n",
       "  'date_range',\n",
       "  'date_ranges',\n",
       "  'datetime_range',\n",
       "  'datetime_ranges',\n",
       "  'element',\n",
       "  'ones',\n",
       "  'repeat',\n",
       "  'time_range',\n",
       "  'time_ranges',\n",
       "  'zeros',\n",
       "  'all',\n",
       "  'any',\n",
       "  'cum_sum',\n",
       "  'cumsum',\n",
       "  'max',\n",
       "  'min',\n",
       "  'sum',\n",
       "  'all_horizontal',\n",
       "  'any_horizontal',\n",
       "  'cum_sum_horizontal',\n",
       "  'cumsum_horizontal',\n",
       "  'max_horizontal',\n",
       "  'mean_horizontal',\n",
       "  'min_horizontal',\n",
       "  'sum_horizontal',\n",
       "  'apply',\n",
       "  'approx_n_unique',\n",
       "  'arange',\n",
       "  'arctan2',\n",
       "  'arctan2d',\n",
       "  'arg_sort_by',\n",
       "  'coalesce',\n",
       "  'col',\n",
       "  'collect_all',\n",
       "  'collect_all_async',\n",
       "  'concat_list',\n",
       "  'concat_str',\n",
       "  'corr',\n",
       "  'count',\n",
       "  'cov',\n",
       "  'cum_count',\n",
       "  'cum_fold',\n",
       "  'cum_reduce',\n",
       "  'cumfold',\n",
       "  'cumreduce',\n",
       "  'date',\n",
       "  'datetime',\n",
       "  'duration',\n",
       "  'exclude',\n",
       "  'field',\n",
       "  'first',\n",
       "  'fold',\n",
       "  'format',\n",
       "  'from_epoch',\n",
       "  'groups',\n",
       "  'head',\n",
       "  'implode',\n",
       "  'int_range',\n",
       "  'int_ranges',\n",
       "  'last',\n",
       "  'lit',\n",
       "  'map',\n",
       "  'map_batches',\n",
       "  'map_groups',\n",
       "  'mean',\n",
       "  'median',\n",
       "  'n_unique',\n",
       "  'nth',\n",
       "  'quantile',\n",
       "  'reduce',\n",
       "  'rolling_corr',\n",
       "  'rolling_cov',\n",
       "  'select',\n",
       "  'std',\n",
       "  'struct',\n",
       "  'tail',\n",
       "  'time',\n",
       "  'var',\n",
       "  'len',\n",
       "  'set_random_seed',\n",
       "  'from_arrow',\n",
       "  'from_dataframe',\n",
       "  'from_dict',\n",
       "  'from_dicts',\n",
       "  'from_numpy',\n",
       "  'from_pandas',\n",
       "  'from_records',\n",
       "  'from_repr',\n",
       "  'SQLContext',\n",
       "  'sql',\n",
       "  'build_info',\n",
       "  'get_index_type',\n",
       "  'show_versions',\n",
       "  'thread_pool_size',\n",
       "  'threadpool_size',\n",
       "  'selectors',\n",
       "  'sql_expr']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
